{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we care about Python?\n",
    "\n",
    "* We can use Python to automate boring a repetitive tasks\n",
    "* We can use Python to clean, transform, and manipulate data (not to mention perform analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data: The Federalist papers\n",
    "\n",
    "\n",
    "* Who wrote the Federalist Papers? Alexander Hamilton, James Madison, or John Jay?  \n",
    "* For more than 150 years, historians argued over the authorship of the 12 essays in _The Federalist Papers_. \n",
    "* It wasn't until 1963 that the mystery was solved by Frederick Mosteller of Harvard University and David Wallace of the University of Chicago. They used statistics and computation to analyze [the style of the text](https://en.wikipedia.org/wiki/Stylometry) and determine the authors of each paper.\n",
    "\n",
    "Full text of _The Federalist Papers_ is available at http://www.gutenberg.org/ebooks/1404\n",
    "\n",
    "### Looking at the data\n",
    "\n",
    "<- Open the file called `federalist_papers.txt` in JupyterLab to see the whole file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data into Python\n",
    "\n",
    "* We can use Python to manipulate the file, but first we need to load it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of The Federalist Papers, by\n",
      "Alexander Hamilton, John Jay, and James Madison\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: The Federalist Papers\n",
      "\n",
      "Author: Alexander Hamilton, John Jay, and James Madison\n",
      "\n",
      "Release Date: July, 1998  [Etext #1404]\n",
      "Posting Date: November 6, 2009\n",
      "\n",
      "Language: English\n",
      "\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK THE FEDERALIST PAPERS ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by The Consitution Society and Anonymous Volunteers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE FEDERALIST PAPERS\n",
      "\n",
      "By Alexander Hamilton, John Jay, and James Madison\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FEDERALIST No. 1\n",
      "\n",
      "General Introduction\n",
      "\n",
      "For the Independent Journal. Saturday, October 27, 1787\n",
      "\n",
      "\n",
      "HAMILTON\n",
      "\n",
      "To the People of the State of New York:\n",
      "\n",
      "AFTER an unequivocal experience of the inefficacy of the subsisting\n",
      "federal government, you are cal\n"
     ]
    }
   ],
   "source": [
    "# Path to our data file (source file)\n",
    "source_file_name = \"federalist_papers.txt\"\n",
    "\n",
    "# open the text file and read it into memory\n",
    "with open(source_file_name) as f:\n",
    "    fed_papers_text = f.read()\n",
    "\n",
    "# Display the first 1000 characters\n",
    "print(fed_papers_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that we have the text file loaded we can begin to manipulate it.\n",
    "* The main thing we want to do is calculate *word frequencies*.\n",
    "    * Let's count the frequency of the words \"while\" and \"whilst\"\n",
    "* So first we need to divide it up into separate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Federalist', 'Papers,', 'by\\nAlexander', 'Hamilton,', 'John', 'Jay,', 'and', 'James', 'Madison\\n\\nThis', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with\\nalmost', 'no', 'restrictions', 'whatsoever.', '', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or\\nre-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included\\nwith', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org\\n\\n\\nTitle:', 'The', 'Federalist', 'Papers\\n\\nAuthor:', 'Alexander', 'Hamilton,', 'John', 'Jay,', 'and', 'James', 'Madison\\n\\nRelease', 'Date:', 'July,', '1998', '', '[Etext', '#1404]\\nPosting', 'Date:', 'November', '6,', '2009\\n\\nLanguage:', 'English\\n\\n\\n***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'FEDERALIST', 'PAPERS', '***\\n\\n\\n\\n\\nProduced', 'by', 'The', 'Consitution', 'Society', 'and', 'Anonymous', 'Volunteers\\n\\n\\n\\n\\n\\nTHE', 'FEDERALIST', 'PAPERS\\n\\nBy', 'Alexander', 'Hamilton,', 'John', 'Jay,']\n"
     ]
    }
   ],
   "source": [
    "# Split the text into separate words based on spaces\n",
    "word_list = fed_papers_text.split(\" \")\n",
    "\n",
    "#display the first 100 words\n",
    "print(word_list[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Will this work?  Are words always separated by spaces?\n",
    "* While there are specialized Python libraries for dealing with text parsing (for example, [spaCy](https://spacy.io/) and the [natural language toolkit](https://www.nltk.org/), we are going to keep it simple.\n",
    "* For now we'll clean our text data in a quick and dirty way by removing the main punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of The Federalist Papers byAlexander Hamilton John Jay and James MadisonThis eBook is for the use of anyone anywhere at no cost and withalmost no restrictions whatsoever  You may copy it give it away orreuse it under the terms of the Project Gutenberg License includedwith this eBook or online at wwwgutenbergorgTitle The Federalist PapersAuthor Alexander Hamilton John Jay and James MadisonRelease Date July 1998  [Etext #1404]Posting Date November 6 2009Language English*** START OF THIS PROJECT GUTENBERG EBOOK THE FEDERALIST PAPERS ***Produced by The Consitution Society and Anonymous VolunteersTHE FEDERALIST PAPERSBy Alexander Hamilton John Jay and James MadisonFEDERALIST No 1General IntroductionFor the Independent Journal Saturday October 27 1787HAMILTONTo the People of the State of New YorkAFTER an unequivocal experience of the inefficacy of the subsistingfederal government you are called upon to deliberate on a newConstitution for the United States of Ameri\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a list of punctuation marks\n",
    "punctuation_marks = ['!','.', ',', ':', ';', '?', '-', '\\n','\\ufeff']\n",
    "# Remove them all from the text and replace with spaces\n",
    "for pm in punctuation_marks:\n",
    "    fed_papers_text = fed_papers_text.replace(pm, '')\n",
    "                     \n",
    "# Display the first 1000 characters\n",
    "print(fed_papers_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice we removed a bunch of the formatting too.\n",
    "* We still have a little bit of text processing to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'federalist', 'papers', 'byalexander', 'hamilton', 'john', 'jay', 'and', 'james', 'madisonthis', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'withalmost', 'no', 'restrictions', 'whatsoever', '', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'orreuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'includedwith', 'this', 'ebook', 'or', 'online', 'at', 'wwwgutenbergorgtitle', 'the', 'federalist', 'papersauthor', 'alexander', 'hamilton', 'john', 'jay', 'and', 'james', 'madisonrelease', 'date', 'july', '1998', '', '[etext', '#1404]posting', 'date', 'november', '6', '2009language', 'english***', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'federalist', 'papers', '***produced', 'by', 'the', 'consitution', 'society', 'and', 'anonymous', 'volunteersthe', 'federalist', 'papersby', 'alexander', 'hamilton', 'john', 'jay']\n"
     ]
    }
   ],
   "source": [
    "# It would be a good idea to convert everything to lower case before we do anything else\n",
    "fed_papers_text = fed_papers_text.lower()\n",
    "\n",
    "# Now let's build a list of words\n",
    "word_list = fed_papers_text.split(\" \")\n",
    "\n",
    "#display the first 100 words\n",
    "print(word_list[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that we have the text a bit more *normalized* we can start counting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of 'while' is: 30\n",
      "The frequency of 'whilst' is: 18\n"
     ]
    }
   ],
   "source": [
    "# find the frequency for \"while\" and \"whilst\"\n",
    "\n",
    "# create some variables to track the count\n",
    "freq_while = 0\n",
    "freq_whilst = 0\n",
    "\n",
    "# loop over every word in the word list\n",
    "for word in word_list:\n",
    "    \n",
    "    # is the word while?\n",
    "    if word == \"while\":\n",
    "        # add one to our while variable\n",
    "        freq_while = freq_while + 1 \n",
    "    # is the word whilst?\n",
    "    elif word == \"whilst\":\n",
    "        # add one to our while variable\n",
    "        freq_whilst = freq_whilst + 1\n",
    "    # the word is neither while or whilst\n",
    "    else:\n",
    "        # just continue looping\n",
    "        continue\n",
    "        \n",
    "print(\"The frequency of 'while' is:\", freq_while)\n",
    "print(\"The frequency of 'whilst' is:\", freq_whilst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look at that! We figured out who wrote the federalist papers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
